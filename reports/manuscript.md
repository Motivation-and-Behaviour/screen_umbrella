# Summary

Children’s engagement in screen time is a complex issue. Parents, policymakers, and educators needing to weigh the risks that sedentary use of screens present alongside the potential benefits for learning and social connectedness. The lack of comprehensive evidence hampers efforts to make an informed decision. As a Lancet editorial<sup>1</sup> suggested, “Our understanding of the benefits, harms, and risks of our rapidly changing digital landscape is sorely lacking.” In this study, we systematically harmonize data from existing meta-analyses of screen time on a range of outcomes, including health, education, and psychology, and identify the most statistically robust relationships. We show that some forms of screen time—such as social media—show consistent evidence of harm for children, with no clear evidence of a benefit. Other relationships are more complex. Video games, for example, are associated with poorer body composition and learning outcomes. However, video games for a specific educational purpose (such as numeracy) are associated with improvements in that subject area. Caregivers must therefore weigh the health risk against the educational benefit. The findings of this study provide parents and other caregivers with the information to make these informed decisions.

# Background

In the 16th century, hysteria reigned around a new technology that threatened to be “confusing and harmful” to the mind. The cause of such concern? The widespread availability of books brought about by the invention of the printing press.<sup>2</sup> In the early 19th century, concerns about schooling “exhausting the children’s brains” followed, with the medical community accepting that excessive study could be a cause of madness.<sup>3</sup> By the 20th century, the invention of the radio was accompanied by assertions that it would distract children from their reading (which by this point was no longer considered confusing and harmful) leading to impaired learning.<sup>4</sup>

Today, the same arguments that were once leveled against reading, schooling, and radio are being made about screen use (e.g., television, mobile phones, and computers).<sup>5</sup> Excessive screen time use is the number one concern parents have about their children’s health and behaviour, ahead of nutrition, bullying, and physical inactivity.<sup>6</sup> Yet, the evidence to support parents’ concerns is inadequate. A Lancet editorial<sup>1</sup> suggested that, “Our understanding of the benefits, harms, and risks of our rapidly changing digital landscape is sorely lacking.”

While some forms of screen use (e.g., television viewing) may be detrimental to health and wellbeing,<sup>7,8</sup> evidence for other forms of screen exposure (e.g., video games or online communication, such as Zoom™) remains less certain and, in some cases, may even be beneficial.<sup>9,10</sup> Thus, according to a Nature Human Behaviour editorial, research to determine the effect of screen exposure on youth is “a defining question of our age”.<sup>11</sup> With concerns over the impact of screen use including education, health, social development, and psychological well-being, a broad overview that identifies potential benefits and risks is needed.

Citing the negative effects of screens on health (e.g., increased risk of obesity) and health-related behaviours (e.g., sleep), guidelines from the World Health Organisation<sup>12</sup> and numerous government agencies<sup>13,14</sup> and statements by expert groups<sup>15</sup> have recommended that young people’s time spent using electronic media devices for entertainment purposes should be limited. For example, the Australian Government guidelines regarding sedentary behaviour recommend that young children (under the age of two) should not spend any time watching screens. They also recommend that children aged 2-5 years should spend a maximum of one hour engaged in recreational sedentary screen use per day, while children aged 5-12 and adolescents should spend no more than two hours. In contrast, some recent evidence suggests that exposure to electronic entertainment media that exceeds these guidelines (e.g., 3-4 hours per day) may not have meaningful adverse effects on children’s behaviour or mental health, and might, in fact, benefit their well-being, as long as this exposure does not reach extreme levels (e.g., 7 hours per day)<sup>16</sup>. Some research also indicates that content (e.g., video games vs television programs) plays an important role in determining the potential benefit or harm of youths’ exposure to screen-based media.<sup>17</sup> Indeed, educational screen time is positively related to educational outcomes.<sup>18</sup> This evidence has led some researchers to argue that a more nuanced approach to screen time guidelines is required.<sup>19</sup>

In 2016, the American Academy of Pediatrics used a narrative review to examine the benefits and risks of children and adolescents’ electronic media<sup>20</sup> as a basis for updating their guidelines about screen use.<sup>15</sup> Since then, a large number of systematic reviews and meta-analyses have provided evidence about the potential benefits and risks of screen use. <span id="r1_2">Yet, no review has examined the evidence available across a broad range of outcome domains, such as physical health, education, physical and cognitive development, behaviour, and well-being. By summarising and synthesising all evidence in one overview, we provide a reference point for the field and allow for easier comparison of risks and benefits for the same behaviour.</span>

In order to synthesise the evidence and support further evidence-based guideline development and refinement, we reviewed published meta-analyses examining the effects of screen use on children and youth. This review synthesises evidence on any outcome of electronic media exposure. Adopting this broad approach allowed us to provide a holistic perspective on the influence of screens on children’s lives. By synthesising across life domains (e.g., school and home), this review provides evidence to inform guidelines and advice for parents, teachers, pediatricians and other professionals in order to maximise human functioning.

# Methods

We prospectively registered our methods on the International Prospective Register of Systematic Reviews (PROSPERO; CRD42017076051). We followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.<sup>21</sup>

### Eligibility criteria

*Population*: To be eligible for inclusion, meta-analyses needed to include meta-analytic effect sizes for children or adolescents (age 0-18 years). <span id="r3_5">We included meta-analyses containing studies that combined data from adults and youth if meta-analytic effect size estimates specific to participants aged 18 years or less could be extracted (i.e., the highest mean age for any individual study included in the meta-analysis was &lt; 18 years). A meta-analysis was still included if the age range exceed 18 years, provided that the mean age was less than 18. We excluded meta-analyses that only contained evidence gathered from adults (age &gt;18 years). </span>

*Exposure*: We included meta-analyses examining all types of electronic screens including (but not necessarily limited to) television, gaming consoles, computers, tablets, and mobile phones. We also included analyses of all types of content on these devices, including (but not necessarily limited to) recreational content (e.g., television programs, movies, games), homework, and communication (e.g., video chat). <span id="r3_6"> In this review we focused on electronic media exposure that would be considered typical for children and youth. That is, exposure that may occur in the home setting, or during schooling. Consistent with this approach, we excluded technology-based treatments for clinical conditions. </span> However, we included studies examining the effect of screen exposure on non-clinical outcomes (e.g., learning) for children and youth with a clinical condition. For example, a meta-analysis of the effect of television watching on learning among adolescents diagnosed with depression would be included. However, a meta-analysis of interventions designed to *treat* clinical depression delivered by a mobile phone app would be excluded. <span id="r3_7"> *Outcomes*: We included all reported outcomes on benefits and risks. </span>

*Publications*: We included meta-analyses (or meta-regressions) of quantitative evidence. To be included, meta-analyses needed to analyse data from studies identified in a systematic review. For our purposes, a systematic review was one in which the authors attempted to acquire all the research evidence that pertained to their research question(s). We excluded meta-analyses that did not attempt to summarise all the available evidence (e.g., a meta-analysis of all studies from one laboratory). We included meta-analyses regardless of the study designs included in the review (e.g., laboratory-based experimental studies, randomised controlled trials, non-randomised controlled trials, longitudinal, cross-sectional, case studies), as long as the studies in the review collected quantitative evidence. We excluded systematic reviews of qualitative evidence. We did not formulate inclusion/exclusion criteria related to the risk of bias of the review. We did, however, employ a risk of bias tool to help interpret the results. We included full-text, peer-reviewed meta-analyses published or ‘in-press’ in English. We excluded conference abstracts and meta-analyses that were unpublished.

### Information sources

We searched records contained in the following databases: Pubmed, MEDLINE, CINAHL, PsycINFO, SPORTDiscus, Education Source, Embase, Cochrane Library, Scopus, Web of Science, ProQuest Social Science Premium Collection, and ERIC. <span id="r3_2">We conducted an initial search on August 17, 2018 and refreshed the search on September 27, 2022.</span> We searched reference lists of included papers in order to identify additional eligible meta-analyses. We also searched PROSPERO to identify relevant protocols and contacted authors to determine if these reviews have been completed and published.

### Search strategy

The search strategy associated with each of the 12 databases can be found in Supplementary File 1. We hand searched reference lists from any relevant umbrella reviews to identify systematic meta-analyses that our search may have missed.

### Selection process

Using Covidence software (Veritas Health Innovation, Melbourne, Australia), two researchers independently screened all titles and abstracts. Two researchers then independently reviewed full-text articles. We resolved disagreements at each stage of the process by consensus, with a third researcher employed, when needed.

### Data items

From each included meta-analysis, two researchers independently extracted data into a custom-designed database. We extracted the following items: First author, year of publication, study design restrictions (e.g., cross-sectional, observational, experimental), region restrictions (e.g., specific countries), earliest and latest study publication dates, sample age (mean), lowest and highest mean age reported, outcomes reported, and exposures reported.

### Study risk of bias assessment

For each meta-analysis, two researchers independently completed the National Health, Lung and Blood Institute’s Quality Assessment of Systematic Reviews and Meta-Analyses tool<sup>22</sup> (see Table @ref(tab:desctable)). We resolved disagreements by consensus, with a third researcher employed when needed. We did not assess risk of bias in the individual studies that were included in each meta-analysis.

### Effect measures

<span id ="r2_17">Two researchers independently extracted all quantitative meta-analytic effect sizes, including moderation results. We excluded effect sizes which were reported as relative risk ratios, as meta-analyses did not contain sufficient information to meaningfully convert. We also excluded effect size estimates when the authors did not provide a sample size. Where possible, we also extracted effect sizes from the primary studies included in each meta-analysis.

To facilitate comparisons, we converted effect sizes to Pearson’s *r* using established formulae.<sup>23–25</sup> Effect sizes on the original metric are provided in Supplementary File 2.</span>

### Synthesis methods

<span id="r3_8">After extracting data, we examined the combinations of exposure and outcomes and removed any effects that appeared multiple times (i.e., in multiple meta-analyses, or with multiple sub-groups in the same meta-analysis), keeping the effect with the largest total sample size. In instances where effect sizes from the same combination of exposure and outcome were drawn from different populations (e.g., children vs adolescents) we retained both estimates in our dataset. </span>

We descriptively present the remaining meta-analytic effect sizes. To remove the differences in approach to meta-analyses across the reviews, we reran the effect size estimate using a random effects meta-analysis via the metafor package<sup>26</sup> in R<sup>27</sup> (version 4.2.2) when the meta-analysis’s authors provided primary study data associated with these effects. When required, we imputed missing sample sizes using mean imputation from the other studies within that review. From our reanalysis we also extracted *I*<sup>2</sup> values. To test for publication bias, we conducted Egger’s test<sup>28</sup> when the number of studies within the review was ten or more,<sup>29</sup> and conducted a test of excess significance.<sup>30</sup> <span id="r2_32">We contacted authors who did not provide primary study data in their published article. Where authors did not provide data in a format that could be re-analysed, we used the published results of their original meta-analysis.</span>

### Evidence assessment criteria

*Statistical Credibility*. We employed a statistical classification approach to grade the credibility of the effect sizes in the literature. To be considered ‘credible’ an effect needed to be derived from a combined sample of &gt;1,000<sup>31</sup> and have non-significant tests of publication bias (i.e., Egger’s test and excess significance test). We performed these analyses, and therefore the review needed to provide usable study-level data in order to be included.

*Consistency of Effect within the Population*. We also examined the consistency of the effect size using the *I*<sup>2</sup> measure. We considered *I*<sup>2</sup> &lt; 50% to indicate effects that were relatively consistent across the population of interest. *I*<sup>2</sup> values of  &gt; 50% were taken to indicate an effect was potentially heterogeneous within the population.

*Direction of Effect*. Finally, we examined the extent to which significance testing suggested screen exposure was associated with benefit, harm, or no effect on outcomes. We used thresholds of *P* &lt; .05 for weak evidence and *P* &lt; 10<sup> − 3</sup> for strong evidence. An effect with statistical credibility but with *P* &gt; .05 was taken to indicate no association of interest.

### Deviations from protocol

We initially planned to include systematic reviews without meta-analyses in a narrative summary alongside the main meta-analytic findings. However, we determined that combining results from the meta-analyses allowed readers to compare relative strength of associations more easily. Readers interested in the relevant systematic reviews (i.e., without meta-analysis) can consult the list of references in Supplementary File 3.

We altered our evidence assessment plan when we identified that, as written, it could not classify precise evidence of null effects (i.e., from large reviews with low heterogeneity and low risk of publication bias) as ‘credible’ because a highly-significant *P*-value was a criteria. This would have significantly harmed knowledge gained from our review as it would have restricted our ability to show where the empirical evidence strongly indicated that there was no association between screen time and a given outcome.

# Results

### Search Results

The searches yielded 50,656 results, of which 28,675 were duplicates. After screening titles and abstracts, we assessed 2,557 full-texts for inclusion. Of those, 224 met the inclusion criteria and we extracted the data from all of these meta-analyses. Figure @ref(fig:prisma) presents the full results of the selection process.

![PRISMA Diagram](../figures/PRISMA%20Diagram.pdf)

The most frequently reported exposures were general screen use (*n* = 45), general TV programs and movies (*n* = 28), physically active video games (*n* = 22), and literacy (abracadabra; in schools) intervention (*n* = 15). Supplementary File 4 provides a list of all exposures identified. The most frequently reported outcomes were general learning (*n* = 46), body composition (*n* = 37), general physical activity (*n* = 22), depression psychological health (*n* = 17), and sleep duration (*n* = 15). In 175 cases there was only one exposure/outcome combination for an age group, with 37 appearing twice, and 26 appearing three or more times. Full characteristics of the included studies are provided in Table @ref(tab:desctable). <span id="r2_23">After removing reviews with duplicate exposure/outcome combinations, our process yielded 275 unique effect/outcome combinations contributed from 118 reviews.</span> These effects represent the findings of 3,103 primary studies comprised of 3,141,213 participants.

The quality of the included meta-analyses was mixed (see Table @ref(tab:desctable)). Most assessed heterogeneity (*n* low risk = 110/118, 93% of meta-analyses), reported the characteristics of the included studies (*n* low risk = 102/118, 86%), and used a comprehensive and systematic search strategy (*n* low risk = 86/118, 73%). Most reviews did not clearly report if their eligibility criteria were predefined (*n* unclear = 84/118, 71%). Many papers also did not complete dual independent screening of abstracts and full text (*n* high risk = 21/118, 18%) or did not clearly report the method of screening (*n* unclear = 42/118, 36%). A similar trend was observed for dual independent quality assessment (*n* high risk = 54/118, 46%; n high risk = 28/118, 24%). Overall, only 8 meta-analyses were graded as low risk of bias on all criteria.

### Education Outcomes

There were 80 unique effects associated with education outcomes, including general learning outcomes, literacy, numeracy, and science. We removed 20 effects that did not provide individual study-level data, 19 effects with samples &lt; 1,000, and 17 effects with a significant Egger’s test or insufficient studies to conduct the test. Effects not meeting one or more of these standards are presented in Supplementary File 5. The remaining 24 effects met our criteria for statistical credibility and are described in Figure @ref(fig:eduplot). These 24 effects came from 17 meta-analytic reviews analysing data from 328 empirical studies with 181,214 individual participants.

![Education outcomes](manuscript_files/figure-markdown_strict/eduplot-1.png)

Among the statistically credible effects, general screen use, television viewing, and video games were all negatively associated with learning. E-books that included narration, as well as touch screen education interventions, and augmented reality education interventions were positively associated with learning. General screen use was negatively associated with literacy outcomes. However, if the screen use involved co-viewing (e.g., watching with a parent), or the content of television programs was educational, the association with literacy was positive and significant at the 95% confidence level (weak evidence). Numeracy outcomes were positively associated with screen-based mathematics interventions and video games that contained numeracy content.

As shown in Figure @ref(fig:eduplot), most of the credible results (14 of 24 effects) showed statistically significant associations, with 99.9% confidence intervals not encompassing zero (strong evidence). The remaining seven associations were significant at the 95% confidence level (weak evidence). All credible effects related to education outcomes were small-to-moderate. Screen-based interventions designed to influence an outcome (e.g., a computer based program designed to enhance learning)<sup>32</sup> tended to have larger effect sizes than exposures that were not specifically intended to influence any of the measured outcomes (e.g., the association between television viewing and learning).<sup>33</sup> The largest effect size observed was for augmented reality-based education interventions on general learning (*r* = 0.33, *k* = 15, *N* = 1, 474). Most effects showed high levels of heterogeneity (21 of 24 with *I*<sup>2</sup> &gt; 50%).

### Health and Health-related Behaviours

We identified 195 unique outcome-exposure combinations associated with health or health-related behaviour outcomes. We removed 35 effects that did not provide individual study-level data, 50 effects with samples &lt; 1,000, and 81 effects with a significant Egger’s test or insufficient studies to conduct the test. No remaining studies showed evidence of excessive significance. Effects not meeting one or more of these standards are presented in Supplementary File 6. The remaining 29 meta-analytic associations met our criteria for credible evidence and are described below (see also Figure @ref(fig:healthplot)). These 29 effects came from 23 meta-analytic reviews analysing data from 380 empirical studies with 1,209,337 individual participants.

![Health and health-related behaviour outcomes](manuscript_files/figure-markdown_strict/healthplot-1.pdf)

Digital advertising of unhealthy foods—both traditional advertising and video games developed by a brand for promotion—were associated with higher unhealthy food intake. Social media use and sexual content were positively associated with risky behaviors (e.g., sexual activity, risk taking, and substance abuse). General screen use was positively associated with depression, with stronger associations observed for adolescents than other groups. Television viewing was negatively correlated with sleep duration, but with stronger evidence only observed for younger children. All forms of screen use (general, television, and video games) were associated with body composition (e.g., higher BMI). Screen-based interventions which target health behaviours appeared mostly effective.

Across the health outcomes, most (19 of 29) effects were statistically significant at the 99.9% confidence interval level, with the remaining six significant at 95% confidence. However, most of the credible effects exhibited high levels of heterogeneity, with all but two having *I*<sup>2</sup> &gt; 75%. Additionally, most effects were small, with the association between screen use and sleep duration the largest at *r* =  − 0.37 (*k* = 10, *N* = 56, 720). Most of the effect sizes (25/29) had an absolute value of *r* &lt; 0.2.

# Discussion

The primary goal of this review was to provide a holistic perspective on the influence of screens on children’s lives across a broad range of outcomes. We found that when meta-analyses examined general screen use, and did not specify the content, context or device, there was strong evidence showing potentially harmful associations with general learning, literacy, body composition, and depression. However, when meta-analyses included a more nuanced examination of exposures, a more complex picture appeared.

As an example, consider children watching television programs—an often cited form of screen time harm. We found robust evidence for a small association with poorer academic performance and literacy skills for general television watching<sup>33</sup>. However, we also found evidence that if the content of the program was educational, or the child was watching the program with a parent (i.e., co-viewing), this exposure was instead associated with better literacy.<sup>34</sup> Thus, parents may play an important role in selecting content that is likely to benefit their children or, perhaps, interact with their children in ways that may foster literacy (e.g., asking their children questions about the program). Similar nuanced findings were observed for video games. The credible evidence we identified showed that video game playing was associated with poorer body composition and learning.<sup>33,35</sup> However, when the video game were designed specifically to teach numeracy, playing these games showed learning benefits.<sup>36</sup> One might expect that video games designed to be physically active could confer health benefits, but none of the meta-analyses examining this hypothesis met our thresholds for statistical credibility (see Supplementary Files 5 & 6) therefore this hypothesis could not be addressed.

Social media was one type of exposure that showed consistent risks to health, with no indication of potential benefit. Social media showed strong evidence of harmful associations with risk taking in general, as well as unsafe sex and substance abuse.<sup>37</sup> These results align with meta-analytic evidence from adults indicating that social media use is also associated with increased risk of depression.<sup>38,39</sup> Recent evidence from social media companies themselves suggest there may also be negative effects of social media on the mental health of young people, especially teenage girls.<sup>40</sup>

One category of exposure appeared to consistently confer benefits: screen-based interventions designed to promote learning or health behaviours. This finding indicates that interventions can be effectively delivered using electronic media platforms, but does not necessarily indicate that screens are more effective than other methods (e.g., face-to-face, printed material). Rather, it reinforces that the content of the screen time may be the most important aspect. The way that a young person interacts with digital screens may also be important. We found evidence that touch screens had strong evidence for benefits on learning,<sup>32</sup> as did augmented reality.<sup>41</sup>

Largely owing to a small number of studies or missing individual study data, there were few age-based conclusions that could be drawn from reviews which met our criteria for statistical certainty. If we expand to include those reviews which did not meet this threshold, there remained no clear pattern although there were some age-specific differences in associations (data avilable in Supplementary Materials). For example, advertising of unhealthy food was associated with unhealthy food choice for young children, but was not statistically significant for other age groups.<sup>42</sup> Conversely, TV programs and movies were more strongly associated with lower physical activity for adolescents than for younger age groups.<sup>43</sup>

Among studies that met our criteria for statistical certainty heterogeneity was high, with almost all effects having *I*<sup>2</sup> &gt; 50%. Much of this heterogeneity is likely explained by differences in measures across pooled studies, or in some cases, the generic nature of some of the exposures. For example, “TV programs and movies” covers a substantial range of content, which may explain the heterogeneous association with education outcomes.

## Implications for Policy and Practice

Broadly, our findings align with the recommendations of others who suggest that current guidelines may be too simplistic, mischaracterise the strength of the evidence, or do not acknowledge the important nuances of the issue.<sup>44–46</sup> Our findings suggest that screen use is a complex issue, with associations based not just on duration and device type, but also on the content and the environment in which the exposure occurs. Many current guidelines simplify this complex relationship as something that should be minimised in all instances.<sup>12,13</sup> We suggest that future guidelines need to embrace the complexity of the issue, to give parents and clinicians specific information to weigh the pros and cons of interactions with screens.

## Implications for Future Research

Screen use research is extensive, varied, and rapidly growing. Reviews tended to be general (e.g., all screen time) and even when more targeted (e.g., social media) nuances related to specific content (e.g., Instagram vs Facebook) have not been meta-analysed or have not produced credible evidence. Fewer than 20% of the effects identified met our criteria for statistical credibility. Most studies which did not meet our critiera failed to provide study-level data (or did not provide sufficent data, such as including effect estimates but not sample sizes). Newer reviews were more likely to provide this information than older reviews, but it highlights the importance of data and code sharing as recommended in the PRISMA guidelines.<sup>21</sup> When study level data was available, many effects were removed because the pooled sample size was small, or because there were fewer than ten studies on which to perform an Egger’s test. It seems that much of the current screen time research is small in scale, and there is a need for larger, high-quality studies.

<span id="r1_1">Our results highlight the need for the field to more carefully consider if the term ‘screen time’ remains appropriate for providing advice to parents. Instead, our results suggest that more nuanced and detailed descriptions of the behaviours to be modified may be required. Rather than suggesting parents limit ‘screen time’, for example, it may be better to suggest that parents promote interactive educational experiences but limit exposure to advertising.</span>

Screen time research has a well-established measurement problem, which impacts the individual studies of this umbrella review. The vast majority of screen time research relies on self-reported data, which not only lacks the nuance required for understanding the effects of screen time, but may also be inaccurate. In one systematic review on screen time and sleep,<sup>7</sup> 66 of the 67 included studies used self-reported data for *both* the exposure and outcome variable. It has been established that self-reported screen time data has questionnable validity. In a meta-analysis of 47 studies comparing self-reported media use with logged measures, Parry et al<sup>47</sup> found that the measures were only moderately correlated (*r* = 0.38), with self-reported problematic usage fairing worse (*r* = 0.25). Indeed, of 622 studies which measured the screen time of 0—6 year-olds, only 69 provided any sort of psychometric properties for their measure, with only 19 studies reporting validity.<sup>48</sup> While some researchers have started using newer methods of capturing screen behaviours—such as wearable cameras<sup>49</sup> or device-based loggers—<sup>50</sup>these are still not widely adopted. It may be that the field of screen time research cannot be sufficiently advanced until accurate, validated, and nuanced measures are more widely available and adopted.

## Strengths and Limitations

Our primary goal for this umbrella review was to provide a high-level synthesis of screen time research, by examining a range of exposures and the associations with a broad scope of outcomes. Our results represent the findings from 3,103 primary studies comprised of 3,141,213 participants. To ensure findings could be compared on a common metric, we extracted and reanalysed individual study data where possible.

Our high-level approach limits the feasibility of examining fine-grained details of the individual studies. For example, we did not examine moderators beyond age, nor did we rate the risk of bias for the individual studies. Thus, our assessment of evidence quality was restricted to statistical credibility, rather than a more complete assessment of quality (e.g., GRADE).<sup>51</sup> As such, we made decisions regarding the credibility of evidence, where others may have used different thresholds or metrics. For this reason, we provide the complete results in the supplementary material, along with the dataset for others to consider alternative criteria. <span id="r1_4">Our high-level approach also means that we could not engage with the specific mechanisms behind each association, and as such, we cannot comment on the evidence for causality. Instead, readers who wish to more deeply understand one specific relationship are directed to the cited review for that effect, where the authors could engage more deeply with the mechanisms.</span> <span id="r3_2_2">In addition, reviews provide only historical evidence which may not keep up with the changing ways children can engage with screens. While our synthesis of the existing evidence provides information about how screens might have influenced children in the past, it is difficult to know if these findings will translate to new forms of technology in the future.</span>

## Conclusions

Screen time is a topic of significant interest, as shown by the wide variety of academic domains involved, parents’ concerns, and the growing pervasiveness into society. Our findings showed that the influence of screen time can be both positive (e.g., educational video games were associated with improved literacy) and negative (e.g., general screen use was associated with poorer body composition). The interplay of these findings show that parents, teachers, and other caregivers need to carefully weigh the pros and cons of each specific activity for potential harms and benefits. However, our findings also suggest that in order to aid caregivers to make this judgement, researchers need to conduct more careful and nuanced measurement and analysis of screen time, with less emphasis on measures that aggregate screen time and instead focus on the content, context, and environment in which the exposure occurs.

# References

<span class="csl-left-margin">1. </span><span class="csl-right-inline">The Lancet. Social media, screen time, and young people’s mental health. *The Lancet* **393**, 611 (2019).</span>

<span class="csl-left-margin">2. </span><span class="csl-right-inline">Blair, A. Reading Strategies for Coping With Information Overload ca.1550-1700. *Journal of the History of Ideas* **64**, 11–28 (2003).</span>

<span class="csl-left-margin">3. </span><span class="csl-right-inline">Bell, A. N. *The sanitarian*. vol. 11 (AN Bell, 1883).</span>

<span class="csl-left-margin">4. </span><span class="csl-right-inline">Dill, K. E. *The Oxford handbook of media psychology*. (Oxford University Press, 2013).</span>

<span class="csl-left-margin">5. </span><span class="csl-right-inline">Wartella, E. A. & Jennings, N. Children and computers: New technology. Old concerns. *The future of children* 31–43 (2000).</span>

<span class="csl-left-margin">6. </span><span class="csl-right-inline">Rhodes, A. *Top ten child health problems: What the public thinks*. (2015).</span>

<span class="csl-left-margin">7. </span><span class="csl-right-inline">Hale, L. & Guan, S. Screen time and sleep among school-aged children and adolescents: A systematic literature review. *Sleep Medicine Reviews* **21**, 50–58 (2015).</span>

<span class="csl-left-margin">8. </span><span class="csl-right-inline">Sweetser, P., Johnson, D., Ozdowska, A. & Wyeth, P. Active versus passive screen time for young children. *Australasian Journal of Early Childhood* **37**, 94–98 (2012).</span>

<span class="csl-left-margin">9. </span><span class="csl-right-inline">Li, X. & Atkins, M. S. Early childhood computer experience and cognitive and motor development. *Pediatrics* **113**, 1715–1722 (2004).</span>

<span class="csl-left-margin">10. </span><span class="csl-right-inline">Warburton, W. & Highfield, K. Children and technology in a smart device world. in *Children, Families and Communities* 195–221 (Oxford University Press, 2017).</span>

<span class="csl-left-margin">11. </span><span class="csl-right-inline">Nature Human Behaviour. Screen time: How much is too much? *Nature* **565**, 265–266 (2019).</span>

<span class="csl-left-margin">12. </span><span class="csl-right-inline">World Health Organization. *Guidelines on physical activity, sedentary behaviour and sleep for children under 5 years of age*. 33 p. (World Health Organization, 2019).</span>

<span class="csl-left-margin">13. </span><span class="csl-right-inline">Australian Government. *Physical activity and exercise guidelines for all Australians*. (2021).</span>

<span class="csl-left-margin">14. </span><span class="csl-right-inline">Canadian Society for Exercise Physiology. *Canadian 24-Hour Movement Guidelines for Children and Youth: An Integration of Physical Activity, Sedentary Behaviour, and Sleep*. (2016).</span>

<span class="csl-left-margin">15. </span><span class="csl-right-inline">Council On Communication and Media. Media Use in School-Aged Children and Adolescents. *Pediatrics* **138**, e20162592 (2016).</span>

<span class="csl-left-margin">16. </span><span class="csl-right-inline">Ferguson, C. J. Everything in Moderation: Moderate Use of Screens Unassociated with Child Behavior Problems. *Psychiatric Quarterly* **88**, 797–805 (2017).</span>

<span class="csl-left-margin">17. </span><span class="csl-right-inline">Przybylski, A. K. & Weinstein, N. A Large-Scale Test of the Goldilocks Hypothesis: Quantifying the Relations Between Digital-Screen Use and the Mental Well-Being of Adolescents. *Psychological Science* **28**, 204–215 (2017).</span>

<span class="csl-left-margin">18. </span><span class="csl-right-inline">Sanders, T., Parker, P. D., del Pozo-Cruz, B., Noetel, M. & Lonsdale, C. Type of screen time moderates effects on outcomes in 4013 children: Evidence from the Longitudinal Study of Australian Children. *International Journal of Behavioral Nutrition and Physical Activity* **16**, 117 (2019).</span>

<span class="csl-left-margin">19. </span><span class="csl-right-inline">Kaye, L. K., Orben, A., Ellis, D. A., Hunter, S. C. & Houghton, S. The Conceptual and Methodological Mayhem of ‘Screen Time’. *International Journal of Environmental Research and Public Health* **17**, 3661 (2020).</span>

<span class="csl-left-margin">20. </span><span class="csl-right-inline">Chassiakos, Y. L. R. *et al.* Children and Adolescents and Digital Media. *Pediatrics* **138**, e20162593 (2016).</span>

<span class="csl-left-margin">21. </span><span class="csl-right-inline">Page, M. J. *et al.* *The PRISMA 2020 statement: An updated guideline for reporting systematic reviews*. (2020) doi:[10.31222/osf.io/v7gm2](https://doi.org/10.31222/osf.io/v7gm2).</span>

<span class="csl-left-margin">22. </span><span class="csl-right-inline">National Health, Lung, and Blood Institute. *Quality Assessment of Systematic Reviews and Meta-Analyses*. (2014).</span>

<span class="csl-left-margin">23. </span><span class="csl-right-inline">Bonett, D. G. Transforming odds ratios into correlations for meta-analytic research. *American Psychologist* **62**, 254–255 (2007).</span>

<span class="csl-left-margin">24. </span><span class="csl-right-inline">Bowman, N. A. Effect Sizes and Statistical Methods for Meta-Analysis in Higher Education. *Research in Higher Education* **53**, 375–382 (2012).</span>

<span class="csl-left-margin">25. </span><span class="csl-right-inline">Jacobs, P. & Viechtbauer, W. Estimation of the biserial correlation and its sampling variance for use in meta-analysis: Biserial Correlation. *Research Synthesis Methods* **8**, 161–180 (2017).</span>

<span class="csl-left-margin">26. </span><span class="csl-right-inline">Viechtbauer, W. *Metafor: Meta-analysis package for r*. (2022).</span>

<span class="csl-left-margin">27. </span><span class="csl-right-inline">R Core Team. *R: A language and environment for statistical computing*. (R Foundation for Statistical Computing, 2022).</span>

<span class="csl-left-margin">28. </span><span class="csl-right-inline">Egger, M., Smith, G. D., Schneider, M. & Minder, C. Bias in meta-analysis detected by a simple, graphical test. *BMJ* **315**, 629–634 (1997).</span>

<span class="csl-left-margin">29. </span><span class="csl-right-inline">Page, M. J., Higgins, J. P. & Sterne, J. A. Chapter 13: Assessing risk of bias due to missing results in a synthesis. in *Cochrane Handbook for Systematic Reviews of Interventions* (eds. Higgins, J. P. et al.) (Cochrane, 2021).</span>

<span class="csl-left-margin">30. </span><span class="csl-right-inline">Ioannidis, J. P. & Trikalinos, T. A. An exploratory test for an excess of significant findings. *Clinical Trials* **4**, 245–253 (2007).</span>

<span class="csl-left-margin">31. </span><span class="csl-right-inline">Papadimitriou, N. *et al.* An umbrella review of the evidence associating diet and cancer risk at 11 anatomical sites. *Nature Communications* **12**, 4579 (2021).</span>

<span class="csl-left-margin">32. </span><span class="csl-right-inline">Xie, H. *et al.* Can Touchscreen Devices be Used to Facilitate Young Children’s Learning? A Meta-Analysis of Touchscreen Learning Effect. *Frontiers in Psychology* **9**, 2580 (2018).</span>

<span class="csl-left-margin">33. </span><span class="csl-right-inline">Adelantado-Renau, M. *et al.* Association Between Screen Media Use and Academic Performance Among Children and Adolescents: A Systematic Review and <span class="nocase">Meta-analysis</span>. *JAMA Pediatrics* **173**, 1058 (2019).</span>

<span class="csl-left-margin">34. </span><span class="csl-right-inline">Madigan, S., McArthur, B. A., Anhorn, C., Eirich, R. & Christakis, D. A. Associations Between Screen Use and Child Language Skills: A Systematic Review and <span class="nocase">Meta-analysis</span>. *JAMA Pediatrics* **174**, 665 (2020).</span>

<span class="csl-left-margin">35. </span><span class="csl-right-inline">Poorolajal, J., Sahraei, F., Mohamdadi, Y., Doosti-Irani, A. & Moradi, L. Behavioral factors influencing childhood obesity: A systematic review and meta-analysis. *Obesity Research & Clinical Practice* **14**, 109–118 (2020).</span>

<span class="csl-left-margin">36. </span><span class="csl-right-inline">Byun, J. & Joung, E. Digital game-based learning for K-12 mathematics education: A meta-analysis. *School Science and Mathematics* **118**, 113–126 (2018).</span>

<span class="csl-left-margin">37. </span><span class="csl-right-inline">Vannucci, A., Simpson, E. G., Gagnon, S. & Ohannessian, C. M. Social media use and risky behaviors in adolescents: A meta-analysis. *Journal of Adolescence* **79**, 258–274 (2020).</span>

<span class="csl-left-margin">38. </span><span class="csl-right-inline">Yoon, S., Kleinman, M., Mertz, J. & Brannick, M. Is social network site usage related to depression? A meta-analysis of Facebookdepression relations. *Journal of Affective Disorders* **248**, 65–72 (2019).</span>

<span class="csl-left-margin">39. </span><span class="csl-right-inline">Vahedi, Z. & Zannella, L. The association between self-reported depressive symptoms and the use of social networking sites (SNS): A meta-analysis. *Current Psychology* **40**, 2174–2189 (2021).</span>

<span class="csl-left-margin">40. </span><span class="csl-right-inline">Seetharaman, G. W., Jeff Horwitz and Deepa. Facebook Knows Instagram Is Toxic for Teen Girls, Company Documents Show. *Wall Street Journal* (2021).</span>

<span class="csl-left-margin">41. </span><span class="csl-right-inline">Tekedere, H. & Göke, H. Examining the Effectiveness of Augmented Reality Applications in Education: A Meta-Analysis. *International Journal of Environmental and Science Education* **11**, 9469–9481 (2016).</span>

<span class="csl-left-margin">42. </span><span class="csl-right-inline">Sadeghirad, B., Duhaney, T., Motaghipisheh, S., Campbell, N. R. C. & Johnston, B. C. Influence of unhealthy food and beverage marketing on children’s dietary intake and preference: A systematic review and meta-analysis of randomized trials. *Obesity Reviews* **17**, 945–959 (2016).</span>

<span class="csl-left-margin">43. </span><span class="csl-right-inline">Marshall, S. J., Biddle, S. J. H., Gorely, T., Cameron, N. & Murdey, I. Relationships between media use, body fatness and physical activity in children and youth: A meta-analysis. *International Journal of Obesity* **28**, 1238–1246 (2004).</span>

<span class="csl-left-margin">44. </span><span class="csl-right-inline">Elson, M. *et al.* Do policy statements on media effects faithfully represent the science? *Advances in Methods and Practices in Psychological Science* **2**, 12–25 (2019).</span>

<span class="csl-left-margin">45. </span><span class="csl-right-inline">Ashton, J. J. & Beattie, R. M. Screen time in children and adolescents: Is there evidence to guide parents and policy? *The Lancet Child & Adolescent Health* **3**, 292–294 (2019).</span>

<span class="csl-left-margin">46. </span><span class="csl-right-inline">Royal College of Paediatrics and Child Health. *The health impacts of screen time: A guide for clinicians and parents.* (2019).</span>

<span class="csl-left-margin">47. </span><span class="csl-right-inline">Parry, D. A. *et al.* A systematic review and meta-analysis of discrepancies between logged and self-reported digital media use. *Nature Human Behaviour* **5**, 1535–1547 (2021).</span>

<span class="csl-left-margin">48. </span><span class="csl-right-inline">Byrne, R., Terranova, C. O. & Trost, S. G. Measurement of screen time among young children aged 0 years: A systematic review. *Obesity Reviews* **22**, (2021).</span>

<span class="csl-left-margin">49. </span><span class="csl-right-inline">Smith, C., Galland, B. C., de Bruin, W. E. & Taylor, R. W. Feasibility of automated cameras to measure screen use in adolescents. *American journal of preventive medicine* **57**, 417–424 (2019).</span>

<span class="csl-left-margin">50. </span><span class="csl-right-inline">Ryding, F. C. & Kuss, D. J. Passive objective measures in the assessment of problematic smartphone use: A systematic review. *Addictive Behaviors Reports* **11**, 100257 (2020).</span>

<span class="csl-left-margin">51. </span><span class="csl-right-inline">Guyatt, G. *et al.* GRADE guidelines: 1. Introduction evidence profiles and summary of findings tables. *Journal of Clinical Epidemiology* **64**, 383–394 (2011).</span>
