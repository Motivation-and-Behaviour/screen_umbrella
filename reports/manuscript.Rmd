---
title: "Benefits and risks associated with children’s and adolescents’ interactions with electronic screens: An umbrella review"
author:
  - name: Taren Sanders
    url: https://orcid.org/0000-0002-4504-6008
    affiliation: Australian Catholic University
    affiliation_url: https://www.acu.edu.au/research/our-research-institutes/institute-for-positive-psychology-and-education
    orcid_id: 0000-0002-4504-6008
  - name: Philip Parker
    url: https://orcid.org/0000-0002-4604-8566 
    affiliation: Australian Catholic University
    affiliation_url: https://www.acu.edu.au/research/our-research-institutes/institute-for-positive-psychology-and-education
    orcid_id: 0000-0002-4604-8566
  - name: Michael Noetel
    url: https://orcid.org/0000-0002-6563-8203 
    affiliation: Australian Catholic University
    affiliation_url: https://www.acu.edu.au/research/our-research-institutes/institute-for-positive-psychology-and-education
    orcid_id: 0000-0002-6563-8203
  - name: Chris Lonsdale
    url: https://orcid.org/000-0002-2523-5565  
    affiliation: Australian Catholic University
    affiliation_url: https://www.acu.edu.au/research/our-research-institutes/institute-for-positive-psychology-and-education
    orcid_id: 000-0002-2523-5565 
date: "`r Sys.Date()`"
repository_url: https://github.com/Motivation-and-Behaviour/screen_umbrella
bibliography: combined.bib
csl: nature.csl
---

```{r setup, include=FALSE}
# This allows distill to render from a targets pipeline
Sys.setenv("RSTUDIO_VERSION" = '1.4.1725')

knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	fig.retina=2
)

# Uncomment to run outside of pipeline
# library(tidyverse)
# library(targets)
# library(xfun)
# library(DiagrammeR)
```

```{r, load-targets}
targets::tar_load(c("prisma", "effects_clean", "reviews_table", "plots", 
           "studies_results", "comparison_plots", "combined_effects", 
           "combined_bib"), 
         store = here::here("_targets"))
```

# Background

In the 16th century, hysteria reigned around a new technology that threatened to be "confusing and harmful" to the mind. The cause of such concern? The widespread availability of books brought about by the invention of the printing press [@blairReadingStrategiesCoping2003]. In the early 19th century, concerns about schooling "exhausting the children's brains" followed, with the medical community accepting that excessive study could be a cause of madness [@bell1883sanitarian]. By the 20th century, the invention of the radio was accompanied by assertions that it would distract children from their reading (which by this point was no longer considered "confusing and harmful") leading to impaired learning [@dill2013oxford].

Today, the same arguments that were once leveled against reading, schooling, and radio are being made about screen time (e.g., TV or computers) [@wartellaChildrenComputersNew2000]. Excessive screen time is the number one concern parents have about their children's health and behaviour, ahead of nutrition, bullying, and physical inactivity [@rhodes2015top]. Yet, the evidence to support parents' concerns is lacking. A 2019 Lancet editorial [@thelancetSocialMediaScreen2019a] suggested that , "Our understanding of the benefits, harms, and risks of our rapidly changing digital landscape is sorely lacking."

While some forms of screen time (e.g., TV viewing) may be detrimental to behaviour and health [@haleScreenTimeSleep2015a;sweetserActivePassiveScreen2012a], evidence for other forms of screen exposure (e.g., video games or online communication, such as Zoom) remains less certain and, in some cases, may even be beneficial [@liEarlyChildhoodComputer2004a;@warburton2017children]. Thus, efforts to determine the effect of screen exposure on youth is "a defining challenge of the digital age" [@orbenAssociationAdolescentWellbeing2019]. With concerns over the impact of screen time including education, health, and psychological well-being, a broad overview that acknowledges screen time's potential benefits and risks is needed.

Citing the negative effects on health (e.g., increased risk of obesity) and health-related behaviours (e.g., sleep), guidelines from numerous government agencies [@australiangovernmentPhysicalActivityExercise2021;@Canadian24HourMovement2016] and statements by expert groups [@AAPMediaUseSchoolAged2016;@whoGuidelinesPhysicalActivity2019] have recommended that young people's time spent using electronic media devices for entertainment purposes should be limited. For example, the Australian Government guidelines regarding sedentary behaviour recommend that young children (under the age of two) should not spend any time watching screens. They also recommend that children aged 2-5 years should spend a maximum of one hour exposed to recreational sedentary screen time per day, while children aged 5-12 and adolescents should spend no more than two hours. In contrast, some recent evidence suggests that exposure to electronic entertainment media that exceeds these guidelines (e.g., 3-4 hours per day) may not have meaningful adverse effects on children's behaviour or mental health [@fergusonEverythingModerationModerate2017], and might, in fact, benefit their well being, as long as this exposure does not reach extreme levels (e.g., 7 hours per day). Some research also indicates that content (e.g., video game vs television program) may also play an important role in determining the potential benefit or harm of youths' exposure to screen-based media [@przybylskiLargeScaleTestGoldilocks2017]. Indeed, educational screen time has been found to be positively related to educational outcomes [@sandersTypeScreenTime2019]. This evidence has led some researchers to argue that a more nuanced approach to screen time guidelines is required.

In 2016, the American Academy of Pediatrics used a narrative review examining the benefits and risks of children and adolescents' electronic media [@chassiakosChildrenAdolescentsDigital2016] as a basis for updating their guidelines [@AAPMediaUseSchoolAged2016]. Since then, a large number of systematic reviews and meta-analyses have provided up-to-date evidence about the potential benefits and risks of screentime. No review has synthesised the evidence available across relevant outcomes, such physical health, health behaviours, education, and psychological well being.

In order to support further evidence-based guideline development and refinement, we reviewed published meta-analyses examining the effects of screen time on young children, children, and adolescents. This review includes the association between electronic media use and any variable that is a plausible outcome of this exposure. Adopting this broad approach allowed us to provide a holistic perspective on the influence of screens on children's lives. By synthesising across life domains, this review provides evidence to support more targeted guidelines and advice for parents, teachers, and other professionals in order to maximise human functioning.

# Methods

### Eligibility criteria

*Population*: To be eligible for inclusion, meta-analyses needed to include meta-analytic effect sizes for children or adolescents ( age 0-18 years). Meta-analyses containing data from adults and youth were included if meta-analytic effect sizes estimates specific to participants aged 18 years or less could be extracted. We excluded meta-analyses that only contained evidence gathered from adults (age >18 years).
*Exposure*: We included meta-analyses examining all types of electronic screens including (but not necessarily limited to) television, gaming consoles, computer, tablet, TV, and mobile phones. We also included analyses of all types of content on these devices, including (but not necessarily limited to) recreational content  (e.g., television programs, movies, games), homework, and communication (e.g., video chat). In this review we adopted a population-level perspective, meaning that we examined electronic media exposure that occurs during typical daily living activities (e.g., home, school-based electronic media exposure). Consistent with this population-level approach, we excluded technology-based treatments for clinical conditions. 
*Outcomes*: We included all reported outcomes.
*Publications*: We included meta-analyses (or meta-regressions) of quantitative evidence. To be included, meta-analyses needed to analyse data from studies identified in a systematic review. For our purposes, a systematic review is a review in which the authors attempted to acquire all the research evidence that pertained to their research question(s). We excluded meta-analyses that did not attempt to summarise all the available evidence (e.g., a meta-analysis of all studies from one laboratory). We included meta-analyses regardless of the study designs included in the review (e.g., laboratory-based experimental studies, randomised controlled trials. non-randomised controlled trials, longitudinal, cross-sectional, case studies), as long as the studies in the review collected quantitative evidence. We excluded systematic reviews of qualitative evidence. We did not formulate inclusion/exclusion criteria related to the risk of bias of the review. We did, however, employ a risk of bias tool to help us interpret the results. We included full-text, peer-reviewed meta-analyses published or ‘in-press’ in English. We excluded conference abstracts and meta-analyses that were unpublished.

### Information sources

We searched records contained in the following databases: Pubmed, MEDLINE, CINAHL, PsycINFO, SPORTDiscus, Education Source, Embase, Cochrane Library, Scopus, Web of Science, ProQuest Social Science Premium Collection, and ERIC. We conducted an initial search on August 17, 2018 and refreshed the search on May 13, 2020. We searched reference lists of included papers in order to identify additional eligible meta-analyses. We also searched PROSPERO to identify relevant protocols and contacted authors to determine if these reviews have been completed and published.

### Search strategy

The search strategy associated with each of the 12 databases can be found [here](https://docs.google.com/document/d/1hz5Dgw0aVOMeXL3vpRXsNtCIbf6dHZTb8uz7wQ29ke4/edit#heading=h.i6znptfz9nwa). We hand searched reference lists from any relevant umbrella reviews to identify systematic meta-analyses that our search may have missed.

### Selection process

Using Covidence software (Veritas Health Innovation, Melbourne, Australia), two researchers independently screened all titles and abstracts. Two researchers then independently reviewed full-text articles. We resolved disagreements at each stage of the process by consensus, with a third researcher employed, when needed.

### Data collection process
Two researchers independently extracted data from the included meta-analyses into a custom-designed database. 

### Data items

From each meta-analysis we extracted the following items: First author, year of publication, earliest and latest study publication dates, sample age, lowest and highest mean age reported, study design restrictions (e.g., cross-sectional, observational, experimental), region restrictions (e.g., specific countries), exposures reported, and outcomes reported.

### Study risk of bias assessment

For each meta-analysis, two researchers independently completed the National Health, Lung and Blood Institute’s Quality Assessment of Systematic Reviews and Meta-Analyses tool [@NHLBIQualityAssessmentSystematic2014]. We resolved disagreements by consensus, with a third researcher employed, when needed. We did not assess risk of bias in the individual studies that were included in each meta-analysis.

### Effect measures

Two researchers independently extracted all quantitative meta-analytic effect sizes, including moderation results. Where possible, they also extracted effect sizes from primary studies included in each meta-analysis. To facilitate comparisons, we converted effect sizes to Pearson’s $r$ using established formulae [@bonettTransformingOddsRatios2007;@bowmanEffectSizesStatistical2012;@jacobsEstimationBiserialCorrelation2017]. We excluded relative risk ratios from this conversion because meta-analyses did not contain sufficient information to do so. Effect sizes on the original metric are provided in supplementary materials.

### Synthesis methods

After extracting data, we examined the combinations of exposure and outcomes and removed any effects that appeared more than once, keeping the effect with the largest total sample size. We excluded effect size estimates when the authors did not provide a sample size. We descriptively present the remaining meta-analytic effect sizes. When the meta-analysis’s authors provided primary study data associated with these effects we reran the effect size estimate using a random effects meta-analysis via the metafor package [@R-metafor] in R [@R-base; version `r paste(R.Version()[c("major", "minor")], collapse = ".")`]. When required, we imputed missing sample sizes using mean imputation from the other studies within that review. From our reanalysis we also extracted I2 values. To test for publication bias, we also conducted Egger's test [@eggerBiasMetaanalysisDetected1997] where the number of studies within the review was ten or more [@pageChapter13Assessing2021], and conducted a test of excess significance [@ioannidisExploratoryTestExcess2007]. We contacted authors who did not provide primary study data in their published article. Where authors did not provide data in a format that could be re-analysed, we used the published results of their original meta-analysis.

# Supplementary Material
